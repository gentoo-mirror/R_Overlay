<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<longdescription>
		Fast, Consistent Tokenization of Natural Language Text // Convert
		natural language text into tokens. Includes tokenizers for
		shingled n-grams, skip n-grams, words, word stems, sentences,
		paragraphs, characters, shingled characters, lines, Penn
		Treebank, regular expressions, as well as functions for
		counting characters, words, and sentences, and a function for
		splitting longer texts into separate documents, each with the
		same number of words.  The tokenizers have a consistent
		interface, and the package is built on the 'stringi' and 'Rcpp'
		packages for  fast yet correct tokenization in 'UTF-8'.
	</longdescription>
</pkgmetadata>
