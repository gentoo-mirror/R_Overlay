<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<longdescription>
		Tools for Preparing Text for Tokenizers // Tokenizers break text
		into pieces that are more usable by machine learning models.
		Many tokenizers share some preparation steps. This package
		provides those shared steps, along with a simple tokenizer.
	</longdescription>
</pkgmetadata>
