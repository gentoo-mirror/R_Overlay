<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pkgmetadata SYSTEM "http://www.gentoo.org/dtd/metadata.dtd">
<pkgmetadata>
	<longdescription>
		Automatically Runs 18 Individual and 14 Ensembles of Models //
		Automatically runs 18 individual models and 14 ensembles on
		numeric data, for a total of 32 models. The package
		automatically returns complete results on all 32 models, 30
		charts and six tables. The user simply provides the tidy data,
		and answers a few questions (for example, how many times would
		you like to resample the data). From there the package randomly
		splits the data into train, test and validation sets, fits each
		of models on the training data, makes predictions on the test
		and validation sets, measures root mean squared error (RMSE),
		removes features above a user-set level of Variance Inflation
		Factor, and has several optional features including scaling all
		numeric data, four different ways to handle strings in the
		data. Perhaps the most significant feature is the package's
		ability to make predictions using the 32 pre trained models on
		totally new (untrained) data if the user selects that feature.
		This feature alone represents a very effective solution to the
		issue of reproducibility of models in data science. The package
		can also randomly resample the data as many times as the user
		sets, thus giving more accurate results than a single run. The
		graphs provide many results that are not typically found. For
		example, the package automatically calculates the Kolmogorov-
		Smirnov test for each of the 32 models and plots a bar chart of
		the results, a bias bar chart of each of the 32 models, as well
		as several plots for exploratory data analysis (automatic
		histograms of the numeric data, automatic histograms of the
		numeric data). The package also automatically creates a summary
		report that can be both sorted and searched for each of the 32
		models, including RMSE, bias, train RMSE, test RMSE, validation
		RMSE, overfitting and duration. The best results on the holdout
		data typically beat the best results in data science
		competitions and published results for the same data set.
	</longdescription>
</pkgmetadata>
